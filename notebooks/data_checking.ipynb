{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and stationary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir1 = '/rds-d2/user/wjm41/hpc-work/datasets/ZINC/real/'\n",
    "dir2 = '/rds-d7/project/rds-ZNFRY9wKoeE/EnamineREAL/'\n",
    "data_dir = dir2 + 'data/'\n",
    "\n",
    "file = open(dir1+'all_tranches.txt', 'r')\n",
    "all_tranches = file.read().splitlines()\n",
    "all_tranches = [line.split('/')[-1].split('.')[0] for line in all_tranches]\n",
    "\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "        \n",
    "\n",
    "existing_dirs = [\n",
    "    data_dir+x for x in os.listdir(data_dir) if os.path.isdir(data_dir+x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% (46570/46570) Downloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46570/46570 [00:58<00:00, 799.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.33% (44863/46570) Scored!\n",
      "3.67% (1707/46570) To Score!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir1 = '/rds-d2/user/wjm41/hpc-work/datasets/ZINC/real/'\n",
    "dir2 = '/rds-d7/project/rds-ZNFRY9wKoeE/EnamineREAL/'\n",
    "data_dir = dir2 + 'data/'\n",
    "\n",
    "file = open(dir1+'all_tranches.txt', 'r')\n",
    "all_tranches = file.read().splitlines()\n",
    "all_tranches = [line.split('/')[-1].split('.')[0] for line in all_tranches]\n",
    "\n",
    "existing_dirs = [\n",
    "    data_dir+x for x in os.listdir(data_dir) if os.path.isdir(data_dir+x)]\n",
    "\n",
    "print('{:.2f}% ({}/{}) Downloaded!'.format(\n",
    "    100*(len(list(set(existing_dirs)))/len(all_tranches)), len(existing_dirs), len(all_tranches)))\n",
    "\n",
    "time.sleep(1)\n",
    "empty_dirs = []\n",
    "pickle_dirs = []\n",
    "smi_dirs = []\n",
    "pickle_and_smi = []\n",
    "scored_dirs = []\n",
    "dirs_to_score = []\n",
    "mpi_dirs_to_score = []\n",
    "\n",
    "for folder in tqdm(existing_dirs, smoothing=0):\n",
    "    # if os.path.isfile(folder+'/mols.sdf'):\n",
    "    #     if os.stat(folder+'/mols.sdf').st_size == 0:\n",
    "    #         empty_dirs.append(folder)\n",
    "\n",
    "    # if os.path.isfile(folder+'/pairs.pickle'):  # check file existence\n",
    "    #     pickle_dirs.append(folder)\n",
    "\n",
    "    # if os.path.isfile(folder+'/mols.smi'):\n",
    "    #     smi_dirs.append(folder)\n",
    "\n",
    "    # if os.path.isfile(folder+'/pairs.pickle') and os.path.isfile(folder+'/mols.smi'):\n",
    "    #     real_pairs = pickle.load(open(folder+'/pairs.pickle', 'rb'))\n",
    "    #     file = open(folder+'/mols.smi', 'r')\n",
    "    #     real_smi = file.read().splitlines()\n",
    "    #     if len(real_smi) == len(real_pairs):\n",
    "    #         pickle_and_smi.append(folder)\n",
    "    # print(os.listdir(folder))\n",
    "    pairs = [file for file in os.listdir(\n",
    "        folder) if \"pairs_mpi_\" in file]\n",
    "    scores = [file for file in os.listdir(\n",
    "        folder) if \"_mpro\" in file and \".csv\" in file]\n",
    "    not_scored = True\n",
    "\n",
    "    # if os.path.isfile(folder+'/scores_mpro.csv'):\n",
    "    #     not_scored = False\n",
    "    # some dirs had MPI processes without pharmacophores\n",
    "    if len(scores) > 0:\n",
    "        not_scored = False\n",
    "    # elif len(pairs) <= len(scores) and len(pairs) != 0:\n",
    "    #     not_scored = False\n",
    "    # elif len(pairs) > len(scores):\n",
    "    #     mpi_dirs_to_score.append(folder)\n",
    "    # else:\n",
    "    #     dirs_to_score.append(folder)\n",
    "\n",
    "    if not not_scored:\n",
    "        scored_dirs.append(folder)\n",
    "    else:\n",
    "        dirs_to_score.append(folder)\n",
    "\n",
    "nonempty_dirs = [x for x in existing_dirs if x not in empty_dirs]\n",
    "\n",
    "# print('{:.2f}% ({}/{}) NonEmpty!'.format(100 *\n",
    "#       (len(list(set(nonempty_dirs)))/len(existing_dirs)), len(nonempty_dirs), len(existing_dirs)))\n",
    "# print('{:.2f}% ({}/{}) Has Pickles!'.format(100 *\n",
    "#       (len(list(set(pickle_dirs)))/len(existing_dirs)), len(pickle_dirs), len(existing_dirs)))\n",
    "# print('{:.2f}% ({}/{}) Has Smiles!'.format(100 *\n",
    "#       (len(list(set(smi_dirs)))/len(existing_dirs)), len(smi_dirs), len(existing_dirs)))\n",
    "# print('{:.2f}% ({}/{}) Has Pickle lengths matching Smiles!'.format(100 *\n",
    "#       (len(list(set(pickle_and_smi)))/len(existing_dirs)), len(pickle_and_smi), len(existing_dirs)))\n",
    "print('{:.2f}% ({}/{}) Scored!'.format(100 *\n",
    "      (len(list(set(scored_dirs)))/len(existing_dirs)), len(scored_dirs), len(existing_dirs)))\n",
    "both = list(set(dirs_to_score).union(set(mpi_dirs_to_score)))\n",
    "print('{:.2f}% ({}/{}) To Score!'.format(100 *\n",
    "                                         (len(both)/len(existing_dirs)), len(both), len(existing_dirs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7946\n"
     ]
    }
   ],
   "source": [
    "dirs_to_score = [x.split('/')[-1] for x in open('dirs/dirs_to_score.txt', 'r').read().splitlines()]\n",
    "mpi_dirs_to_score = [x.split(\n",
    "    '/')[-1] for x in open('dirs/mpi_dirs_to_score.txt', 'r').read().splitlines()]\n",
    "\n",
    "logs = open(\n",
    "    '../data/EnamineREAL/slurm_logs/subm_score_mpro.out', 'r').read().splitlines()\n",
    "mpi_logs = str(open('../data/EnamineREAL/slurm_logs/subm_score_mpi_mpro.out', 'r').read().splitlines())\n",
    "\n",
    "# for line in logs:\n",
    "#     if dirs_to_score[10] in line:\n",
    "#         print(line)\n",
    "\n",
    "# for line in mpi_logs:\n",
    "#     if mpi_dirs_to_score[0] in line:\n",
    "#         print(line)\n",
    "n = 0\n",
    "for mpi_dir in mpi_dirs_to_score:\n",
    "    # print(mpi_dir)\n",
    "    if mpi_dir in mpi_logs:\n",
    "        n+=1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir2+'/folds/all_folds.txt', 'w')\n",
    "for line in existing_dirs:\n",
    "    f.write(line.split('/')[-1]+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rds-d2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15143/15143 [02:39<00:00, 94.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.23% Scored!\n",
      "len(dirs_to_score): 532\n",
      "len(mpi_dirs_to_score): 645\n",
      "rds-d7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29941/29941 [05:39<00:00, 88.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.09% Scored!\n",
      "len(dirs_to_score): 194\n",
      "len(mpi_dirs_to_score): 1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "### SCORING ###\n",
    "\n",
    "def count_scoring(path, write=False):\n",
    "    if path==dir1:\n",
    "        print('rds-d2')\n",
    "        dirs = nonempty_dirs1\n",
    "    elif path==dir2:\n",
    "        print('rds-d7')\n",
    "        dirs = nonempty_dirs2\n",
    "    else:\n",
    "        raise Exception('Wrong directory supplied!')\n",
    "    time.sleep(1)\n",
    "    scored_dirs = []\n",
    "    dirs_to_score = []\n",
    "    mpi_dirs_to_score = []\n",
    "    for i,folder in tqdm(enumerate(dirs), total = len(dirs)):\n",
    "\n",
    "            pairs = [file for file in os.listdir(path+folder) if \"pairs_mpi_\" in file]\n",
    "            scores = [file for file in os.listdir(path+folder) if \"_mac\" in file and \".csv\" in file]\n",
    "\n",
    "            not_scored = True\n",
    "\n",
    "            if os.path.isfile(path+folder+'/scores_mac.csv'):\n",
    "                not_scored = False\n",
    "            elif len(pairs) <= len(scores) and len(pairs)!=0: # some dirs had MPI processes without pharmacophores\n",
    "                not_scored = False\n",
    "            elif len(pairs) > len(scores):\n",
    "#                 print(len(pairs))\n",
    "#                 print(len(scores))\n",
    "                mpi_dirs_to_score.append(folder)\n",
    "            else:\n",
    "                dirs_to_score.append(folder)\n",
    "\n",
    "            if not not_scored:\n",
    "                scored_dirs.append(folder)\n",
    "        \n",
    "    print('{:.2f}% Scored!'.format(100*(len(list(set(scored_dirs)))/len(dirs))))\n",
    "\n",
    "    print('len(dirs_to_score): {}'.format(len(dirs_to_score)))\n",
    "    print('len(mpi_dirs_to_score): {}'.format(len(mpi_dirs_to_score)))\n",
    "    \n",
    "    if write:\n",
    "        f = open(path+'scored_dirs.txt', 'w')\n",
    "        for line in scored_dirs:\n",
    "            f.write(line+'\\n')\n",
    "        f.close()\n",
    "        f = open(path+'to_score_mac.txt', 'w')\n",
    "        for line in dirs_to_score:\n",
    "            f.write(line+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        f = open(path+'to_score_mpi_mac.txt', 'w')\n",
    "        for line in mpi_dirs_to_score:\n",
    "            f.write(line+'\\n')\n",
    "        f.close()\n",
    "\n",
    "count_scoring(dir1, write=True)\n",
    "count_scoring(dir2, write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('{:.2f}% ({}/{}) Downloaded!'.format(\n",
    "    100*(len(list(set(existing_dirs)))/len(all_tranches)), len(existing_dirs), len(all_tranches)))\n",
    "\n",
    "time.sleep(1)\n",
    "empty_dirs = []\n",
    "pickle_dirs = []\n",
    "smi_dirs = []\n",
    "pickle_and_smi = []\n",
    "scored_dirs = []\n",
    "dirs_to_score = []\n",
    "mpi_dirs_to_score = []\n",
    "\n",
    "for folder in tqdm(existing_dirs, smoothing=0):\n",
    "    # if os.path.isfile(folder+'/mols.sdf'):\n",
    "    #     if os.stat(folder+'/mols.sdf').st_size == 0:\n",
    "    #         empty_dirs.append(folder)\n",
    "\n",
    "    if os.path.isfile(folder+'/pairs.pickle'): # check file existence \n",
    "        pickle_dirs.append(folder)  \n",
    "\n",
    "    if os.path.isfile(folder+'/mols.smi'):\n",
    "        smi_dirs.append(folder)\n",
    "\n",
    "    if os.path.isfile(folder+'/pairs.pickle') and os.path.isfile(folder+'/mols.smi'):\n",
    "        real_pairs = pickle.load(open(folder+'/pairs.pickle', 'rb'))\n",
    "        file = open(folder+'/mols.smi', 'r')\n",
    "        real_smi = file.read().splitlines()    \n",
    "        if len(real_smi) == len(real_pairs):\n",
    "            pickle_and_smi.append(folder)\n",
    "        else:\n",
    "            print(folder)\n",
    "\n",
    "    pairs = [file for file in os.listdir(\n",
    "        folder) if \"pairs_mpi_\" in file]\n",
    "    scores = [file for file in os.listdir(\n",
    "        folder) if \"_mac\" in file and \".csv\" in file]\n",
    "\n",
    "    not_scored = True\n",
    "\n",
    "    if os.path.isfile(folder+'/scores_mac.csv'):\n",
    "        not_scored = False\n",
    "    elif len(pairs) <= len(scores) and len(pairs)!=0: # some dirs had MPI processes without pharmacophores\n",
    "        not_scored = False\n",
    "    elif len(pairs) > len(scores):\n",
    "        mpi_dirs_to_score.append(folder)\n",
    "    else:\n",
    "        dirs_to_score.append(folder)\n",
    "\n",
    "    if not not_scored:\n",
    "        scored_dirs.append(folder)\n",
    "nonempty_dirs = [x for x in existing_dirs if x not in empty_dirs]\n",
    "\n",
    "print('{:.2f}% ({}/{}) NonEmpty!'.format(100 *\n",
    "      (len(list(set(nonempty_dirs)))/len(existing_dirs)), len(nonempty_dirs), len(existing_dirs)))\n",
    "print('{:.2f}% ({}/{}) Has Pickles!'.format(100 *\n",
    "      (len(list(set(pickle_dirs)))/len(pickle_dirs)), len(pickle_dirs), len(existing_dirs)))\n",
    "print('{:.2f}% ({}/{}) Has Smiles!'.format(100 *\n",
    "      (len(list(set(smi_dirs)))/len(existing_dirs)), len(smi_dirs), len(existing_dirs)))\n",
    "print('{:.2f}% ({}/{}) Has Pickle lengths matching Smiles!'.format(100 *\n",
    "      (len(list(set(pickle_and_smi)))/len(existing_dirs)), len(pickle_and_smi), len(existing_dirs)))\n",
    "print('{:.2f}% ({}/{}) Scored!'.format(100 *\n",
    "      (len(list(set(scored_dirs)))/len(existing_dirs)), len(scored_dirs), len(existing_dirs)))\n",
    "print('len(dirs_to_score): {}'.format(len(dirs_to_score)))\n",
    "print('len(mpi_dirs_to_score): {}'.format(len(mpi_dirs_to_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46570/46570 [08:42<00:00, 89.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.02% (38663/46570) Has Pickles!\n",
      "17.15% (7988/46570) Has MPI Pickles!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "\n",
    "dirs_to_score = []\n",
    "mpi_dirs_to_score = []\n",
    "\n",
    "for folder in tqdm(existing_dirs, smoothing=0):\n",
    "\n",
    "    if os.path.isfile(folder+'/pairs.pickle'): # check file existence \n",
    "        dirs_to_score.append(folder)\n",
    "\n",
    "    pairs = [file for file in os.listdir(\n",
    "        folder) if \"pairs_mpi_\" in file]\n",
    "\n",
    "    if len(pairs)>0:  # check file existence\n",
    "        mpi_dirs_to_score.append(folder)\n",
    "\n",
    "print('{:.2f}% ({}/{}) Has Pickles!'.format(100 *\n",
    "      (len(list(set(dirs_to_score)))/len(existing_dirs)), len(dirs_to_score), len(existing_dirs)))\n",
    "print('{:.2f}% ({}/{}) Has MPI Pickles!'.format(100 *\n",
    "      (len(list(set(mpi_dirs_to_score)))/len(existing_dirs)), len(mpi_dirs_to_score), len(existing_dirs)))\n",
    "both = list(set(dirs_to_score).intersection(set(mpi_dirs_to_score)))\n",
    "print('{:.2f}% ({}/{}) Has Both!'.format(100 *\n",
    "                                         (len(both)/len(existing_dirs)), len(both), len(existing_dirs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34% (625/46570) Has Both!\n",
      "98.83% (46026/46570) total pickles!\n"
     ]
    }
   ],
   "source": [
    "both = list(set(dirs_to_score).intersection(set(mpi_dirs_to_score)))\n",
    "print('{:.2f}% ({}/{}) Has Both!'.format(100 *\n",
    "        (len(both)/len(existing_dirs)), len(both), len(existing_dirs)))\n",
    "\n",
    "total = list(set(dirs_to_score).union(set(mpi_dirs_to_score)))\n",
    "print('{:.2f}% ({}/{}) total pickles!'.format(100 *\n",
    "    (len(total)/len(existing_dirs)), len(total), len(existing_dirs)))\n",
    "\n",
    "\n",
    "f = open(dir2+'/folds/pickle_folds.txt', 'w')\n",
    "for line in dirs_to_score:\n",
    "    f.write(line.split('/')[-1]+'\\n')\n",
    "f.close()\n",
    "f = open(dir2+'/folds/mpi_pickle_folds.txt', 'w')\n",
    "for line in mpi_dirs_to_score:\n",
    "    f.write(line.split('/')[-1]+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rds-d2\n",
      "97.33% NonEmpty!\n",
      "rds-d7\n",
      "96.43% NonEmpty!\n"
     ]
    }
   ],
   "source": [
    "def find_nonempty(path):\n",
    "    if path==dir1:\n",
    "        print('rds-d2')\n",
    "        dirs = dirs1\n",
    "    elif path==dir2:\n",
    "        print('rds-d7')\n",
    "        dirs = dirs2\n",
    "    else:\n",
    "        raise Exception('Wrong directory supplied!')\n",
    "        \n",
    "    empty_dirs = []\n",
    "    for folder in dirs:\n",
    "        if os.path.isfile(path+folder+'/mols.sdf'):\n",
    "            if os.stat(path+folder+'/mols.sdf').st_size==0:\n",
    "                empty_dirs.append(folder)\n",
    "    nonempty_dirs = [x for x in dirs if x not in empty_dirs]\n",
    "\n",
    "    print('{:.2f}% NonEmpty!'.format(100*(len(list(set(nonempty_dirs)))/len(dirs))))\n",
    "    \n",
    "    return nonempty_dirs\n",
    "\n",
    "nonempty_dirs1 = find_nonempty(dir1)\n",
    "nonempty_dirs2 = find_nonempty(dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1183.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scored_dirs1 = open(dir1+'missing.txt', 'r').read().splitlines()\n",
    "scored_dirs2 = open(dir2+'missing.txt', 'r').read().splitlines()\n",
    "\n",
    "def find_missing(dir, dirs):\n",
    "    missing_dirs = []\n",
    "    for i,folder in tqdm(enumerate(dirs), total = len(dirs)):\n",
    "#         logging.info(folder)\n",
    "        if not os.path.isfile(dir+folder+'/topN_mac.csv'):\n",
    "            missing_dirs.append(folder)\n",
    "    print(len(missing_dirs))\n",
    "#     f = open(dir+'missing.txt', 'w')\n",
    "#     for line in missing_dirs:\n",
    "#         f.write(line+'\\n')\n",
    "#     f.close()\n",
    "    \n",
    "# find_missing(dir1, scored_dirs1)\n",
    "find_missing(dir2, scored_dirs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1035/1035 [00:00<00:00, 1857.26it/s]\n",
      "  2%|▏         | 128/6144 [00:00<00:04, 1274.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rds-d2\n",
      "415 empty dirs\n",
      "0 small dirs\n",
      "0 big dirs\n",
      "Total file size: 0.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6144/6144 [00:03<00:00, 1686.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rds-d7\n",
      "1110 empty dirs\n",
      "1244 bad dirs left\n",
      "1 small dirs\n",
      "0 big dirs\n",
      "Total file size: 0.0 bytes\n",
      "Average file size: 0.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "MB = 1048576\n",
    "\n",
    "def \n",
    "\n",
    "bad_dirs1 = open(dir+'bad_dirs.txt','r').read().split()\n",
    "\n",
    "n_bad = 0\n",
    "n_zero = 0\n",
    "tot_size = 0\n",
    "\n",
    "to_proc = []\n",
    "to_proc_big = []\n",
    "\n",
    "for bad_dir in tqdm(bad_dirs1):\n",
    "#     print(os.listdir(dir+bad_dir))\n",
    "#     gz_files = [file for file in os.listdir(dir+bad_dir) if '.gz' in file]\n",
    "#     if len(gz_files)!=0:\n",
    "#         n_bad+=1\n",
    "    if os.path.isfile(dir+bad_dir+'/mols.sdf') and not os.path.isfile(dir+bad_dir+'/done.txt'):\n",
    "        if os.stat(dir+bad_dir+'/mols.sdf').st_size==0:\n",
    "            n_zero+=1\n",
    "        else:\n",
    "            size = os.stat(dir+bad_dir+'/mols.sdf').st_size\n",
    "#             tot_size += size\n",
    "            if size > MB:\n",
    "                if not os.path.isfile(dir+bad_dir+'/scores11_mac.csv'):\n",
    "                    tot_size += size\n",
    "                    to_proc_big.append(bad_dir)\n",
    "                else:\n",
    "                    c_date = datetime.datetime.fromtimestamp(pathlib.Path(dir+bad_dir+'/scores11_mac.csv').stat().st_ctime)\n",
    "                    if c_date.day!=16 and c_date!=15:\n",
    "                        print(c_date.day)\n",
    "                        tot_size += size\n",
    "                        to_proc_big.append(bad_dir)\n",
    "            else:\n",
    "#                 print(bad_dir)\n",
    "                to_proc.append(bad_dir)\n",
    "#             print(file_size(dir+bad_dir+'/mols.sdf'))\n",
    "#         print(bad_dir)\n",
    "#         print(datetime.datetime.fromtimestamp(pathlib.Path(dir+bad_dir+'/mols.sdf').stat().st_mtime))\n",
    "#         print(datetime.datetime.fromtimestamp(pathlib.Path(dir+bad_dir+'/mols.sdf').stat().st_ctime))\n",
    "#     if not os.path.isfile(dir+bad_dir+'/mols.sdf'):\n",
    "#         n_bad+=1\n",
    "        \n",
    "# print('{} bad dirs left'.format(n_bad))\n",
    "tot_len = len(to_proc) + len(to_proc_big)\n",
    "print('rds-d2')\n",
    "print('{} empty dirs'.format(n_zero))\n",
    "print('{} small dirs'.format(len(to_proc)))\n",
    "print('{} big dirs'.format(len(to_proc_big)))\n",
    "print('Total file size: {}'.format(convert_bytes(tot_size)))        \n",
    "if tot_len!=0:\n",
    "    print('Average file size: {}'.format(convert_bytes(tot_size/tot_len)))\n",
    "\n",
    "# f = open(dir+'small_mac.txt','w')\n",
    "# for line in to_proc:\n",
    "#     f.write(line+'\\n')\n",
    "# f.close()\n",
    "f = open(dir+'big_mac.txt','w')\n",
    "for line in to_proc_big:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "bad_dirs2 = open(dir2+'bad_dirs.txt','r').read().split()\n",
    "\n",
    "n_bad = 0\n",
    "n_zero = 0\n",
    "tot_size = 0\n",
    "\n",
    "to_proc = []\n",
    "to_proc_big = []\n",
    "# big_bad = []\n",
    "for bad_dir in tqdm(bad_dirs2):\n",
    "    if os.path.isfile(dir2+bad_dir+'/mols.sdf'):\n",
    "        if os.stat(dir2+bad_dir+'/mols.sdf').st_size==0:\n",
    "            n_zero+=1\n",
    "        else:\n",
    "            size = os.stat(dir2+bad_dir+'/mols.sdf').st_size\n",
    "            if size > MB:\n",
    "                if not os.path.isfile(dir2+bad_dir+'/scores11_mac.csv'):\n",
    "                    tot_size += size\n",
    "                    to_proc_big.append(bad_dir)\n",
    "                else:\n",
    "                    c_date = datetime.datetime.fromtimestamp(pathlib.Path(dir2+bad_dir+'/scores11_mac.csv').stat().st_ctime)\n",
    "                    if c_date.day not in [15, 16, 17, 18]:\n",
    "#                         print(c_date.day)\n",
    "                        tot_size += size\n",
    "                        to_proc_big.append(bad_dir)\n",
    "            else:\n",
    "                to_proc.append(bad_dir)\n",
    "#             print(file_size(dir2+bad_dir+'/mols.sdf'))\n",
    "\n",
    "# #     print(os.listdir(dir+bad_dir))\n",
    "# #     gz_files = [file for file in os.listdir(dir+bad_dir) if '.gz' in file]\n",
    "# #     if len(gz_files)!=0:\n",
    "# #         n_bad+=1\n",
    "# #     if os.path.isfile(dir2+bad_dir+'/mols.sdf'):\n",
    "# #         print(bad_dir)\n",
    "# #         print(datetime.datetime.fromtimestamp(pathlib.Path(dir2+bad_dir+'/mols.sdf').stat().st_mtime))\n",
    "# #         print(datetime.datetime.fromtimestamp(pathlib.Path(dir2+bad_dir+'/mols.sdf').stat().st_ctime))\n",
    "    if not os.path.isfile(dir2+bad_dir+'/mols.sdf'):\n",
    "        n_bad+=1\n",
    "#         big_bad.append(bad_dir)\n",
    "tot_len = len(to_proc) + len(to_proc_big)\n",
    "print('rds-d7')\n",
    "print('{} empty dirs'.format(n_zero))\n",
    "print('{} bad dirs left'.format(n_bad))\n",
    "print('{} small dirs'.format(len(to_proc)))\n",
    "print('{} big dirs'.format(len(to_proc_big)))\n",
    "print('Total file size: {}'.format(convert_bytes(tot_size)))        \n",
    "if tot_len!=0:\n",
    "    print('Average file size: {}'.format(convert_bytes(tot_size/tot_len)))\n",
    "\n",
    "# bad_tranches = []\n",
    "# for line in data:\n",
    "#     for bad_dir in big_bad:\n",
    "#         if bad_dir in line:\n",
    "#             bad_tranches.append(line)\n",
    "# print(len(bad_tranches))\n",
    "# f = open(dir2+'bad_tranches.txt','w')\n",
    "# for line in bad_tranches:\n",
    "#     f.write(line+'\\n')\n",
    "# f.close()\n",
    "# f = open(dir2+'small_mac.txt','w')\n",
    "# for line in to_proc:\n",
    "#     f.write(line+'\\n')\n",
    "# f.close()\n",
    "f = open(dir2+'big_mac.txt','w')\n",
    "for line in to_proc_big:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dirs1 = open(dir+'bad_dirs.txt','r').read().split()\n",
    "print(len(bad_dirs1))\n",
    "bad_tranches = []\n",
    "for line in data:\n",
    "    for bad_dir in bad_dirs1:\n",
    "        if bad_dir in line:\n",
    "            bad_tranches.append(line)\n",
    "print(len(bad_tranches))\n",
    "f = open(dir+'bad_tranches.txt','w')\n",
    "for line in bad_tranches:\n",
    "    f.write(line+'\\n')\n",
    "    \n",
    "bad_dirs2 = open(dir2+'bad_dirs.txt','r').read().split()\n",
    "print(len(bad_dirs2))\n",
    "bad_tranches = []\n",
    "for line in data:\n",
    "    for bad_dir in bad_dirs2:\n",
    "        if bad_dir in line:\n",
    "            bad_tranches.append(line)\n",
    "print(len(bad_tranches))\n",
    "f = open(dir2+'bad_tranches.txt','w')\n",
    "for line in bad_tranches:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15558/15558 [1:48:43<00:00,  2.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num bad dirs: 651\n",
      "0\n",
      "651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "rescore_dirs = []\n",
    "bad_dirs = []\n",
    "for path in tqdm(dirs1):\n",
    "        pairs = [file for file in os.listdir(dir+path) if \"pairs_mpi_\" in file]\n",
    "        try:\n",
    "            if len(pairs)!=0:\n",
    "                for n in range(len(pairs)):\n",
    "                    smi_len = len(open(dir+path+'/mols'+str(n)+'.smi','r').read().splitlines())\n",
    "                    pickle_len = len(pickle.load(open(dir+path+'/pairs_mpi_'+str(n)+'.pickle','rb')))\n",
    "#                     score_len = len(np.load(dir+path+'/scores'+str(n)+'.npy'))\n",
    "\n",
    "#                     if smi_len != score_len:\n",
    "#                         rescore_dirs.append(path)\n",
    "#                         break\n",
    "                    if smi_len != pickle_len:\n",
    "                        bad_dirs.append(path)\n",
    "                        break\n",
    "            else:\n",
    "                smi_len = len(open(dir+path+'/mols.smi','r').read().splitlines())\n",
    "                pickle_len = len(pickle.load(open(dir+path+'/pairs.pickle','rb')))\n",
    "#                 score_len = len(np.load(dir+path+'/scores.npy'))\n",
    "    \n",
    "#                 if smi_len != score_len:\n",
    "#                     rescore_dirs.append(path)\n",
    "                if smi_len != pickle_len:\n",
    "                    bad_dirs.append(path)\n",
    "        except FileNotFoundError as ex:\n",
    "#             bad_dirs.append(path)\n",
    "#             print(dir+path)\n",
    "#             print(ex)\n",
    "            continue\n",
    "print('Num bad dirs: {}'.format(len(rescore_dirs + bad_dirs)))\n",
    "print(len(rescore_dirs))\n",
    "print(len(bad_dirs))\n",
    "f = open(dir+'bad_dirs.txt', 'w')\n",
    "for line in rescore_dirs + bad_dirs:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31051/31051 [4:55:00<00:00,  1.75it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num bad dirs: 5199\n",
      "0\n",
      "5199\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "rescore_dirs = []\n",
    "bad_dirs = []\n",
    "for path in tqdm(dirs2):\n",
    "        pairs = [file for file in os.listdir(dir2+path) if \"pairs_mpi_\" in file]\n",
    "        try:\n",
    "            if len(pairs)!=0:\n",
    "                for n in range(len(pairs)):\n",
    "                    smi_len = len(open(dir2+path+'/mols'+str(n)+'.smi','r').read().splitlines())\n",
    "                    pickle_len = len(pickle.load(open(dir2+path+'/pairs_mpi_'+str(n)+'.pickle','rb')))\n",
    "#                     score_len = len(np.load(dir+path+'/scores'+str(n)+'.npy'))\n",
    "\n",
    "#                     if smi_len != score_len:\n",
    "#                         rescore_dirs.append(path)\n",
    "#                         break\n",
    "                    if smi_len != pickle_len:\n",
    "                        bad_dirs.append(path)\n",
    "                        break\n",
    "            else:\n",
    "                smi_len = len(open(dir2+path+'/mols.smi','r').read().splitlines())\n",
    "                pickle_len = len(pickle.load(open(dir2+path+'/pairs.pickle','rb')))\n",
    "#                 score_len = len(np.load(dir+path+'/scores.npy'))\n",
    "    \n",
    "#                 if smi_len != score_len:\n",
    "#                     rescore_dirs.append(path)\n",
    "                if smi_len != pickle_len:\n",
    "                    bad_dirs.append(path)\n",
    "        except FileNotFoundError as ex:\n",
    "            bad_dirs.append(path)\n",
    "#             print(dir+path)\n",
    "#             print(ex)\n",
    "            continue\n",
    "print('Num bad dirs: {}'.format(len(rescore_dirs + bad_dirs)))\n",
    "print(len(rescore_dirs))\n",
    "print(len(bad_dirs))\n",
    "f = open(dir2+'bad_dirs.txt', 'w')\n",
    "for line in rescore_dirs + bad_dirs:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rescore_dirs2 = []\n",
    "bad_dirs2 = []\n",
    "for path in tqdm(dirs2):\n",
    "        pairs = [file for file in os.listdir(dir2+path) if \"pairs_mpi_\" in file]\n",
    "        try:\n",
    "            if len(pairs)!=0:\n",
    "                for n in range(len(pairs)):\n",
    "                    smi_len = len(open(dir2+path+'/mols'+str(n)+'.smi','r').read().splitlines())\n",
    "#                     pickle_len = len(pickle.load(open(dir+path+'/pairs_mpi_'+str(n)+'.pickle','rb')))\n",
    "                    score_len = len(np.load(dir2+path+'/scores'+str(n)+'.npy'))\n",
    "\n",
    "                    if smi_len != score_len:\n",
    "                        rescore_dirs2.append(path)\n",
    "                        break\n",
    "            else:\n",
    "                smi_len = len(open(dir2+path+'/mols.smi','r').read().splitlines())\n",
    "#                 pickle_len = len(pickle.load(open(dir+path+'/pairs.pickle','rb')))\n",
    "                score_len = len(np.load(dir2+path+'/scores.npy'))\n",
    "    \n",
    "                if smi_len != score_len:\n",
    "                    rescore_dirs2.append(path)\n",
    "        except FileNotFoundError as ex:\n",
    "            bad_dirs2.append(path)\n",
    "#             print(dir2+path)\n",
    "#             print(ex)\n",
    "            continue\n",
    "print('Num bad dirs: {}'.format(len(rescore_dirs2 + bad_dirs)))\n",
    "print(len(rescore_dirs2))\n",
    "print(len(bad_dirs2))\n",
    "f = open(dir2+'bad_dirs.txt', 'w')\n",
    "for line in rescore_dirs2 + bad_dirs2:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir+'dirs1.txt', 'w')\n",
    "for fold in dirs1:\n",
    "    f.write(fold+'\\n')\n",
    "f.close()\n",
    "f = open(dir2+'dirs2.txt', 'w')\n",
    "for fold in dirs2:\n",
    "    f.write(fold+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIR1 = /rds-d2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dirs = 0\n",
    "big_size = 0\n",
    "big_folds = []\n",
    "\n",
    "med_dirs = 0\n",
    "med_size = 0\n",
    "med_folds = []\n",
    "\n",
    "small_dirs = 0\n",
    "small_size = 0\n",
    "small_folds = []\n",
    "\n",
    "hundred = 104857600\n",
    "\n",
    "for folder in tqdm(folders):\n",
    "    if os.path.isfile(dir+folder+'/mols.sdf') and not os.path.isfile(dir+folder+'/mols_mpi_0.pickle'):\n",
    "        if os.stat(dir+folder+'/mols.sdf').st_size > 4*hundred:\n",
    "            big_dirs+=1\n",
    "            big_size+=os.stat(dir+folder+'/mols.sdf').st_size\n",
    "            big_folds.append(folder)\n",
    "        elif os.stat(dir+folder+'/mols.sdf').st_size > hundred:\n",
    "            med_dirs+=1\n",
    "            med_size+=os.stat(dir+folder+'/mols.sdf').st_size\n",
    "            med_folds.append(folder)\n",
    "        elif os.stat(dir+folder+'/mols.sdf').st_size!=0:\n",
    "            small_dirs+=1\n",
    "            small_size+=os.stat(dir+folder+'/mols.sdf').st_size\n",
    "            small_folds.append(folder)\n",
    "            \n",
    "print('\\nBig sdf Prop: {:.2f}%'.format(100*big_dirs/len(folders)))\n",
    "print('Big sdf Size: {}'.format(convert_bytes(big_size)))\n",
    "print('\\nMed sdf Prop: {:.2f}%'.format(100*med_dirs/len(folders)))\n",
    "print('Med sdf Size: {}'.format(convert_bytes(med_size)))\n",
    "print('\\nSmall sdf Prop: {:.2f}%'.format(100*small_dirs/len(folders)))\n",
    "print('Small sdf Size: {}'.format(convert_bytes(small_size)))\n",
    "\n",
    "print(len(big_folds))\n",
    "f = open(dir+'bigs.txt', 'w')\n",
    "for line in big_folds:\n",
    "    f.write(line+'\\n')\n",
    "print(len(med_folds))\n",
    "f = open(dir+'meds.txt', 'w')\n",
    "for line in med_folds:\n",
    "    f.write(line+'\\n')\n",
    "print(len(small_folds))\n",
    "f = open(dir+'smalls.txt', 'w')\n",
    "for line in small_folds:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "big_dirs = 0\n",
    "big_size = 0\n",
    "big_folds = []\n",
    "\n",
    "med_dirs = 0\n",
    "med_size = 0\n",
    "med_folds = []\n",
    "\n",
    "small_dirs = 0\n",
    "small_size = 0\n",
    "small_folds = []\n",
    "\n",
    "hundred = 104857600\n",
    "\n",
    "for folder in tqdm(folders):\n",
    "    if os.path.isfile(dir+folder+'/mols.pickle') and not os.path.isfile(dir+folder+'/mols0.pickle'):\n",
    "        if os.stat(dir+folder+'/mols.pickle').st_size > 4*hundred:\n",
    "            big_dirs+=1\n",
    "            big_size+=os.stat(dir+folder+'/mols.pickle').st_size\n",
    "            big_folds.append(folder)\n",
    "        elif os.stat(dir+folder+'/mols.pickle').st_size > hundred:\n",
    "            med_dirs+=1\n",
    "            med_size+=os.stat(dir+folder+'/mols.pickle').st_size\n",
    "            med_folds.append(folder)\n",
    "        elif os.stat(dir+folder+'/mols.pickle').st_size!=0:\n",
    "            small_dirs+=1\n",
    "            small_size+=os.stat(dir+folder+'/mols.pickle').st_size\n",
    "            small_folds.append(folder)\n",
    "for folder in tqdm(folders):\n",
    "    if os.path.isfile(dir+folder+'/mols.pickle') and not os.path.isfile(dir+folder+'/mols0.pickle'):\n",
    "        if os.stat(dir+folder+'/mols.pickle').st_size > 4*hundred:\n",
    "            big_dirs+=1\n",
    "            big_size+=os.stat(dir+folder+'/mols.pickle').st_size\n",
    "            big_folds.append(folder)\n",
    "        elif os.stat(dir+folder+'/mols.pickle').st_size > hundred:\n",
    "            med_dirs+=1\n",
    "            med_size+=os.stat(dir+folder+'/mols.pickle').st_size\n",
    "            med_folds.append(folder)\n",
    "        elif os.stat(dir+folder+'/mols.pickle').st_size!=0:\n",
    "            small_dirs+=1\n",
    "            small_size+=os.stat(dir+folder+'/mols.pickle').st_size\n",
    "            small_folds.append(folder)           \n",
    "print('\\nBig pickle Prop: {:.2f}%'.format(100*big_dirs/len(folders)))\n",
    "print('Big pickle Size: {}'.format(convert_bytes(big_size)))\n",
    "print('\\nMed pickle Prop: {:.2f}%'.format(100*med_dirs/len(folders)))\n",
    "print('Med pickle Size: {}'.format(convert_bytes(med_size)))\n",
    "print('\\nSmall pickle Prop: {:.2f}%'.format(100*small_dirs/len(folders)))\n",
    "print('Small pickle Size: {}'.format(convert_bytes(small_size)))\n",
    "\n",
    "print(len(big_folds))\n",
    "f = open(dir+'bigs.txt', 'a')\n",
    "for line in big_folds:\n",
    "    f.write(line+'\\n')\n",
    "print(len(med_folds))\n",
    "f = open(dir+'meds.txt', 'a')\n",
    "for line in med_folds:\n",
    "    f.write(line+'\\n')\n",
    "print(len(small_folds))\n",
    "f = open(dir+'smalls.txt', 'a')\n",
    "for line in small_folds:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_folds = open(dir+'/meds.txt').read().splitlines()\n",
    "\n",
    "\n",
    "print(len(big_folds))\n",
    "del_folds = []\n",
    "\n",
    "for folder in tqdm(big_folds):\n",
    "    if os.path.isfile(dir+folder+'/mols.pickle'):\n",
    "        should_keep=False\n",
    "        \n",
    "        if not os.path.isfile(dir+folder+'/pairs.pickle'):\n",
    "            should_keep=True\n",
    "        else:    \n",
    "            for n in range(4):\n",
    "                if not os.path.isfile(dir+folder+'/pairs_mpi_'+str(n)+'.pickle'):\n",
    "                    should_keep=True\n",
    "                    break\n",
    "        if not should_keep:\n",
    "            del_folds.append(folder)\n",
    "            \n",
    "print(len(del_folds))\n",
    "\n",
    "f = open(dir+'to_del.txt', 'w')\n",
    "for line in del_folds:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIR2 = /rds-d7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = open(dir2+'/to_clean.txt').read().splitlines()\n",
    "\n",
    "del_folds = []\n",
    "for folder in tqdm(to_clean):\n",
    "#     if os.path.isfile(dir2+folder+'/mols.sdf'):\n",
    "        \n",
    "    should_del=True\n",
    "    for n in range(11):\n",
    "        if os.stat(dir2+folder+'/mols'+str(n)+'.smi').st_size==0:\n",
    "            should_del=False\n",
    "            break\n",
    "    if not should_del:\n",
    "        del_folds.append(folder)\n",
    "print(del_folds)\n",
    "\n",
    "f = open(dir2+'to_clean.txt', 'w')\n",
    "for line in del_folds:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dirs = []\n",
    "pickle_dirs2 = []\n",
    "pickle_mpi_dirs = []\n",
    "pickle_mpi_dirs2 = []\n",
    "no_pickledirs = []\n",
    "\n",
    "for i,folder in tqdm(enumerate(folders), total = len(folders)):\n",
    "    if folder in existing_dirs:\n",
    "        if os.path.isfile(dir+folder+'/pairs.pickle'):\n",
    "            pickle_dirs.append(folder)\n",
    "        elif os.path.isfile(dir+folder+'/pairs_mpi_0.pickle') or os.path.isfile(dir+folder+'/pairs_mpi_4.pickle'):\n",
    "            pickle_mpi_dirs.append(folder)\n",
    "        elif os.path.isfile(dir2+folder+'/pairs.pickle'): \n",
    "            pickle_dirs2.append(folder)\n",
    "        elif os.path.isfile(dir2+folder+'/pairs_mpi_0.pickle') or os.path.isfile(dir2+folder+'/pairs_mpi_4.pickle'):\n",
    "            pickle_mpi_dirs2.append(folder)\n",
    "        else:\n",
    "            no_pickledirs.append(folder)\n",
    "            \n",
    "done_dirs = pickle_dirs + pickle_dirs2 + pickle_mpi_dirs + pickle_mpi_dirs2\n",
    "print(len(done_dirs))\n",
    "\n",
    "print('{:.2f}% Pickled!'.format(100*(len(list(set(done_dirs)))/len(folders))))\n",
    "\n",
    "print('Not yet pickled:')\n",
    "print(no_pickledirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir+'to_check.txt', 'w')\n",
    "for line in pickle_mpi_dirs:\n",
    "    f.write(line+'\\n')\n",
    "print(len(pickle_mpi_dirs))\n",
    "f = open(dir2+'to_check.txt', 'w')\n",
    "for line in pickle_mpi_dirs2:\n",
    "    f.write(line+'\\n')\n",
    "print(len(pickle_mpi_dirs2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from frag_funcs import return_pcore_dataframe\n",
    "\n",
    "import pickle \n",
    "\n",
    "fail_dirs = []\n",
    "fail_dirs2 = []\n",
    "\n",
    "for i,folder in tqdm(enumerate(folders), total = len(folders)):\n",
    "    if os.path.isfile(dir+folder+'/pairs.pickle') and not os.path.isfile(dir+folder+'/scores.npy'):\n",
    "        \n",
    "        with open(dir+folder+'/pairs.pickle', 'rb') as handle:\n",
    "            try:\n",
    "                zinc_pairs = pickle.load(handle)     \n",
    "            except Exception:\n",
    "                fail_dirs.append(i)\n",
    "                \n",
    "    if os.path.isfile(dir2+folder+'/pairs.pickle') and not os.path.isfile(dir2+folder+'/scores.npy'): \n",
    "        with open(dir2+folder+'/pairs.pickle', 'rb') as handle:\n",
    "            try:\n",
    "                zinc_pairs = pickle.load(handle)     \n",
    "            except Exception:\n",
    "                fail_dirs2.append(i)\n",
    "            \n",
    "failed_dirs = fail_dirs + fail_dirs2\n",
    "print(len(failed_dirs))\n",
    "\n",
    "print('{:.2f}% Failed pickles'.format(100*(len(list(set(failed_dirs)))/len(folders))))\n",
    "\n",
    "f = open(dir+'fail_dirs.txt', 'w')\n",
    "for i in fail_dirs:\n",
    "    f.write(data[i]+'\\n')\n",
    "print(len(fail_dirs))\n",
    "\n",
    "f = open(dir2+'fail_dirs.txt', 'w')\n",
    "for i in fail_dirs2:\n",
    "    f.write(data[i]+'\\n')\n",
    "print(len(fail_dirs2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dirs = []\n",
    "pickle_dirs2 = []\n",
    "pickle_mpi_dirs = []\n",
    "pickle_mpi_dirs2 = []\n",
    "\n",
    "for i,folder in tqdm(enumerate(folders), total = len(folders)):\n",
    "    if folder in existing_dirs and folder not in failed_dirs:\n",
    "        if os.path.isfile(dir+folder+'/pairs.pickle') and not os.path.isfile(dir+folder+'/scores.npy'):\n",
    "            pickle_dirs.append(folder)\n",
    "        elif os.path.isfile(dir+folder+'/pairs_mpi_0.pickle') and not os.path.isfile(dir+folder+'/scores0.npy'):\n",
    "            pickle_mpi_dirs.append(folder)\n",
    "        elif os.path.isfile(dir2+folder+'/pairs.pickle') and not os.path.isfile(dir2+folder+'/scores.npy'): \n",
    "            pickle_dirs2.append(folder)\n",
    "        elif os.path.isfile(dir2+folder+'/pairs_mpi_0.pickle') and not os.path.isfile(dir2+folder+'/scores0.npy'):\n",
    "            pickle_mpi_dirs2.append(folder)\n",
    "            \n",
    "scored_dirs = pickle_dirs + pickle_dirs2 + pickle_mpi_dirs + pickle_mpi_dirs2\n",
    "print(len(scored_dirs))\n",
    "\n",
    "print('{:.2f}% Pickled but not Scored!'.format(100*(len(list(set(scored_dirs)))/len(folders))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir+'to_score.txt', 'w')\n",
    "for line in pickle_dirs:\n",
    "    f.write(line+'\\n')\n",
    "print(len(pickle_dirs))\n",
    "f = open(dir+'to_score_mpi.txt', 'w')\n",
    "for line in pickle_mpi_dirs:\n",
    "    f.write(line+'\\n')\n",
    "print(len(pickle_mpi_dirs))\n",
    "f = open(dir2+'to_score.txt', 'w')\n",
    "for line in pickle_dirs2:\n",
    "    f.write(line+'\\n')\n",
    "print(len(pickle_dirs2))\n",
    "f = open(dir2+'to_score_mpi.txt', 'w')\n",
    "for line in pickle_mpi_dirs2:\n",
    "    f.write(line+'\\n')\n",
    "print(len(pickle_mpi_dirs2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_dirs = []\n",
    "scored_dirs2 = []\n",
    "for i,folder in tqdm(enumerate(folders), total = len(folders)):\n",
    "    if folder in existing_dirs:\n",
    "        if os.path.isfile(dir+folder+'/scores.npy'):\n",
    "            scored_dirs.append(folder)\n",
    "        elif os.path.isfile(dir2+folder+'/scores.npy'):\n",
    "            scored_dirs2.append(folder)\n",
    "        elif os.path.isfile(dir+folder+'/scores0.npy'):\n",
    "            scored_dirs.append(folder)\n",
    "        elif os.path.isfile(dir2+folder+'/scores0.npy'):\n",
    "            scored_dirs2.append(folder)\n",
    "            \n",
    "scored_dirs = scored_dirs + scored_dirs2\n",
    "print(len(scored_dirs))\n",
    "\n",
    "print('{:.2f}% Scored!'.format(100*(len(list(set(scored_dirs)))/len(folders))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# print(time.localtime(os.path.getmtime(dir2+folders[0]+'/scores.npy')))\n",
    "\n",
    "old_dirs = []\n",
    "old_dirs_mpi = []\n",
    "for i,folder in tqdm(enumerate(folders), total = len(folders)):\n",
    "    if folder in existing_dirs:\n",
    "        if os.path.isfile(dir+folder+'/scores.npy'):\n",
    "            if time.localtime(os.path.getmtime(dir+folder+'/scores.npy'))[2]<10:\n",
    "                if os.path.isfile(dir+folder+'/pairs.pickle'):\n",
    "                    old_dirs.append(folder)\n",
    "print(len(old_dirs))\n",
    "\n",
    "print('{:.2f}% Need Rescoring!'.format(100*(len(list(set(old_dirs)))/len(folders))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir+'rescore.txt', 'w')\n",
    "for line in old_dirs:\n",
    "    f.write(line+'\\n')\n",
    "print(len(old_dirs))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_size = 0\n",
    "fail_size2 = 0\n",
    "\n",
    "weird_dirs = []\n",
    "weird_dirs2 = []\n",
    "print('DIR #1')\n",
    "for fold in fail_dirs:\n",
    "    try:\n",
    "        fail_size+=os.stat(dir+fold+'/mols.pickle').st_size\n",
    "    except Exception:\n",
    "        weird_dirs.append(fold)\n",
    "\n",
    "print('DIR #2')\n",
    "for fold in fail_dirs2:\n",
    "    try:\n",
    "        fail_size2+=os.stat(dir2+fold+'/mols.pickle').st_size\n",
    "    except Exception:\n",
    "        weird_dirs2.append(fold)\n",
    "        \n",
    "print('Fail Size: {}'.format(convert_bytes(fail_size)))\n",
    "print('Fail2 Size: {}'.format(convert_bytes(fail_size2)))\n",
    "\n",
    "f = open(dir+'weird_dirs.txt', 'w')\n",
    "for line in weird_dirs:\n",
    "    f.write(line+'\\n')\n",
    "print(len(weird_dirs))\n",
    "\n",
    "f = open(dir2+'weird_dirs.txt', 'w')\n",
    "for line in weird_dirs2:\n",
    "    f.write(line+'\\n')\n",
    "print(len(weird_dirs2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "        \n",
    "dirs = 0\n",
    "\n",
    "smi_dir = 0\n",
    "sdf_dir = 0\n",
    "pickle_dir = 0\n",
    "score_dir = 0\n",
    "\n",
    "smi_size = 0\n",
    "sdf_size = 0\n",
    "pickle_size = 0\n",
    "score_size = 0\n",
    "\n",
    "pickle_dirs = []\n",
    "for folder in tqdm(folders):\n",
    "    if os.path.isdir(dir+folder):\n",
    "        dirs+=1\n",
    "    if os.path.isfile(dir+folder+'/mols.smi'):\n",
    "        smi_dir+=1\n",
    "        smi_size+=os.stat(dir+folder+'/mols.smi').st_size\n",
    "    if os.path.isfile(dir+folder+'/mols.sdf'):\n",
    "        if os.stat(dir+folder+'/mols.sdf').st_size!=0:\n",
    "            sdf_dir+=1\n",
    "            sdf_size+=os.stat(dir+folder+'/mols.sdf').st_size\n",
    "    if os.path.isfile(dir+folder+'/pairs.pickle'):\n",
    "        pickle_dir+=1\n",
    "        pickle_size+=os.stat(dir+folder+'/pairs.pickle').st_size\n",
    "        pickle_dirs.append(folder)\n",
    "    if os.path.isfile(dir+folder+'/scores.npy'):\n",
    "        score_dir+=1\n",
    "        score_size+=os.stat(dir+folder+'/scores.npy').st_size\n",
    "        \n",
    "print('Download Completion: {:.2f}%'.format(100*dirs/len(folders)))\n",
    "\n",
    "print('\\nSMI Completion: {:.2f}%'.format(100*smi_dir/len(folders)))\n",
    "print('SMI Size: {}'.format(convert_bytes(smi_size)))\n",
    "print('Estimated SMI Size: {}'.format(convert_bytes(smi_size*len(folders)/score_dir)))\n",
    "\n",
    "print('\\nSDF Completion: {:.2f}%'.format(100*sdf_dir/len(folders)))\n",
    "print('SDF Size: {}'.format(convert_bytes(sdf_size)))\n",
    "print('Estimated SDF Size: {}'.format(convert_bytes(sdf_size*len(folders)/sdf_dir)))\n",
    "\n",
    "print('\\nPickle Completion: {:.2f}%'.format(100*pickle_dir/len(folders)))\n",
    "print('Pickle Size: {}'.format(convert_bytes(pickle_size)))\n",
    "print('Estimated Pickle Size: {}'.format(convert_bytes(pickle_size*len(folders)/pickle_dir)))\n",
    "\n",
    "print('\\nScore Completion: {:.2f}%'.format(100*score_dir/len(folders)))\n",
    "print('Estimated Score Size: {}'.format(convert_bytes(score_size*len(folders)/score_dir)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b09d7c221980357d8f26c1325f29a0c217782a36e96a133a3258ff922138085"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('felix_md': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
