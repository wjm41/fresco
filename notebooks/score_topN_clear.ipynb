{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Descriptors, MolFromSmiles, MolToSmiles\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit.Chem import Descriptors, MolFromSmiles\n",
    "\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "dir1 = '/rds-d2/user/wjm41/hpc-work/datasets/ZINC/real/'\n",
    "\n",
    "dir2 = '/rds-d7/project/rds-ZNFRY9wKoeE/EnamineREAL/'\n",
    "\n",
    "scored_dirs1 = open(dir1+'scored_dirs.txt', 'r').read().splitlines()\n",
    "scored_dirs2 = open(dir2+'scored_dirs.txt', 'r').read().splitlines()\n",
    "\n",
    "# dirs1 = [x for x in os.listdir(dir1) if os.path.isdir(dir1+x)]\n",
    "# \n",
    "# dirs2 = [x for x in os.listdir(dir2) if os.path.isdir(dir2+x)]\n",
    "\n",
    "def proc_df(path, N=1000):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['2body_score'].notnull()]\n",
    "    if len(df)!=0:\n",
    "        df = df.apply(filter_small, axis=1)\n",
    "        df = df[df['keep']]\n",
    "        df = df.sort_values(by='2body_score')\n",
    "        df = df.iloc[:min(N,len(df))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Top-N\n",
    "\n",
    "N=10000\n",
    "\n",
    "df_all = []\n",
    "for i,folder in tqdm(enumerate(scored_dirs1), total = len(scored_dirs1)):\n",
    "        if os.path.isfile(dir1+folder+'/topN_mac.csv'):\n",
    "            df = pd.read_csv(dir1+folder+'/topN_mac.csv')\n",
    "            df_all.append(df)\n",
    "        \n",
    "df_all = pd.concat(df_all).sort_values(by='2body_score').drop_duplicates(subset=['smiles'], keep='first')\n",
    "\n",
    "df_all_2 = []\n",
    "for i,folder in tqdm(enumerate(scored_dirs2), total = len(scored_dirs2)):\n",
    "        if os.path.isfile(dir2+folder+'/topN_mac.csv'):\n",
    "            df = pd.read_csv(dir2+folder+'/topN_mac.csv')\n",
    "            df_all_2.append(df)\n",
    "        \n",
    "df_all_2 = pd.concat(df_all_2).sort_values(by='2body_score').drop_duplicates(subset=['smiles'], keep='first')\n",
    "\n",
    "df_tot = pd.concat([df_all, df_all_2]).sort_values(by='2body_score').drop_duplicates(subset=['smiles'], keep='first')\n",
    "df_tot.iloc[:min(N, len(df_all_2))].to_csv(dir2+'topN_final_mac.csv', index=False)\n",
    "print(len(df_tot))\n",
    "\n",
    "df_all.iloc[:min(N, len(df_all))].to_csv(dir1+'topN_mac.csv', index=False)\n",
    "\n",
    "df_all_2.iloc[:min(N, len(df_all_2))].to_csv(dir2+'topN_mac.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_tot.drop_duplicates(subset=['smiles'], keep='first')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mols2grid\n",
    "\n",
    "N = 10000\n",
    "# df1 = df1.rename(columns={'smiles':'SMILES'})\n",
    "# df2 = df2.rename(columns={'smiles':'SMILES'})\n",
    "\n",
    "mols2grid.display(pd.read_csv(dir2+'topN_final_mac.csv').iloc[:N].rename(columns={'smiles':'SMILES'}), template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES', '2body_score'])\n",
    "# mols2grid.display(df2, template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(dir2+'topN_final_acc_true.csv')\n",
    "df2 = pd.read_csv('~/topN_final_acc.csv')\n",
    "# print(len(df1.drop_duplicates(subset=['smiles'], keep='first')))\n",
    "print(df1.equals(df2))\n",
    "smiles_x = df1['smiles'].values\n",
    "smiles_y = df2['smiles'].values\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "print(len(intersection(smiles_x, smiles_y)))\n",
    "print(len(df1[df1['dir'].str.contains('rds-d2')]))\n",
    "print(len(df2[df2['dir'].str.contains('rds-d2')]))\n",
    "\n",
    "df_overlap = df1.merge(df2, how='inner', on='smiles')\n",
    "# print(len(df_overlap[df_overlap.duplicated(subset='smiles')]))\n",
    "# print(len(df_overlap))\n",
    "print(len(df_overlap[df_overlap['dir_x'].str.contains('rds-d2')]))\n",
    "print(len(df_overlap[df_overlap['dir_x'].str.contains('rds-d7')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.drop_duplicates(subset=['smiles'], keep='first'))\n",
    "df1[['smiles','2body_score']].to_csv('~/topN_mpro.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitted_mols = [\n",
    "    'Cc1ccc(NCc2nnc3n(C)c(=O)c4ccccc4n23)cc1C',\n",
    "    'O=C(Nc1ccc2c(=O)cc[nH]c2c1)c1ccc2ccncc2c1',\n",
    "    'Cc1cn2ccc(C(=O)Nc3nc(-c4cnn(C)c4)cs3)cc2n1',\n",
    "    'O=C(Cc1c[nH]c2cc(Cl)ccc12)Nc1cccc2[nH]c(=O)[nH]c12',\n",
    "    'Cc1nnc(CNc2ccc3nnc(-c4ccccc4)n3n2)o1',\n",
    "    'CCn1c(CNc2nnc(-c3nccn3C)o2)nc2ccccc21',\n",
    "    'CN(Cc1nnc2ccccn12)C(=O)c1ccnc2ccccc12',\n",
    "    'Cc1cc(N2CCC(C)N(Cc3ccccc3)CC2)n2ncnc2n1',\n",
    "    'O=C(Nc1nn2cnnc2s1)c1csc(-c2ccccc2)n1',\n",
    "    'Cc1cn2c(CNC(=O)c3cnn4ccccc34)c(C)nc2s1',\n",
    "    'N#CCc1cccc(NC(=O)c2cnn3cc(Br)cnc23)n1',\n",
    "    'Cc1ccc(Br)nc1C(=O)NC(C)c1nnc2c(=O)[nH]ccn12',\n",
    "    'O=C(NNc1nc(Br)cn2ccnc12)c1nccn2ccnc12',\n",
    "    'O=C(NNc1cc(O)nc2ncccc12)c1ccc2[nH]ccc2c1',\n",
    "    'Cc1cc(C(=O)Nc2cnc3nccn3c2)nn1-c1ccc(F)cc1',\n",
    "    'Cn1ccn2c(CNC(=O)c3ccc4ncsc4c3)nnc2c1=O',\n",
    "    'Cn1c(NC(=O)Cc2csc3nccn23)nc2ccc(F)cc21',\n",
    "    'O=C(N/N=c1\\cc[nH]c2ccccc12)c1ccc2ncccc2c1',\n",
    "    'Cc1cc(O)c2cc(NC(=O)c3cnn4ccc(C)nc34)ccc2n1',\n",
    "    'Cc1cccc2ncnc(NC(C)c3ccc4[nH]c(=O)[nH]c4c3)c12',\n",
    "    'Cc1[nH]c2ccccc2c1C(=O)NNc1nc2cccnc2s1',\n",
    "    'O=C(Nc1cnc2nccn2c1)c1cn2c(Br)cnc2s1',\n",
    "    'O=C(Nc1cccc2nccnc12)c1c[nH]c2cc([N+](=O)[O-])ccc12',\n",
    "    'Cc1ccc(C(=O)Nc2c(-c3cnn(C)c3)nc3ccccn23)cn1',\n",
    "    'c1ccc2oc(C3CCCN(Cc4cnc5cnccn45)C3)nc2c1',\n",
    "    'Cn1cnnc1-c1cccc(NS(=O)(=O)c2c(Cl)nc3sccn23)c1',\n",
    "    'Cn1c(=O)oc2cc(S(=O)(=O)Nc3ccc4ncccc4c3)ccc21',\n",
    "    'CC(NC(=O)c1c(Cl)nc2ccccn12)c1nnc2ccccn12',\n",
    "    'CC(NC(=O)c1nccc2cccnc12)c1ccc2[nH]c(=O)oc2c1',\n",
    "    'Cc1noc2ncc(CNc3ccc(-c4nnnn4C)cc3)cc12',\n",
    "    'CC(NC(=O)c1cnc2sccn2c1=O)c1nc2ccccc2n1C',\n",
    "    'c1cc(CN2CCCC(c3nnc4ccccn34)C2)n2ccnc2c1',\n",
    "    'Cc1nc2sccn2c1CN(C)C(=O)c1cn2ccccc2n1',\n",
    "    'CN(Cc1nc2ccccc2s1)C(=O)c1ccc2c(c1)nnn2C',\n",
    "    'CC(Cc1nc2ccccc2s1)Nc1ccc2nnnn2n1',\n",
    "    'Cc1csc2ncc(C(=O)Nc3cccc4ncccc34)c(=O)n12',\n",
    "    'O=C(NNc1nc2ccccc2[nH]1)c1cc(O)nc2ccccc12',\n",
    "    'O=C(Nc1cccc2cc[nH]c12)c1cccc2[nH]c(=O)oc12',\n",
    "    'Cn1c(NC(=O)c2cccnc2-n2cccn2)nc2cc(F)ccc21',\n",
    "    'Cc1nn2c(CNc3ccc(Cn4cncn4)cc3)c(C)nc2s1',\n",
    "    'CC(CNC(=O)c1cnc2ccccn12)Nc1nc2ccccc2o1',\n",
    "    'Cc1nc2cc(C(=O)NNc3nc4ccncc4s3)ccc2o1',\n",
    "    'Cc1nn(C)c2nc(Cl)cc(NNC(=O)c3ccnc4[nH]nnc34)c12',\n",
    "    'COc1ccc(CNCCc2cn3ccsc3n2)cc1OC(F)F',\n",
    "    'CC(NC(=O)c1ccc2oc(=S)[nH]c2c1)c1nnc2ccccn12',\n",
    "]\n",
    "\n",
    "def return_canon(smi):\n",
    "    mol = MolFromSmiles(smi)\n",
    "    Chem.RemoveStereochemistry(mol)\n",
    "    return MolToSmiles(mol)\n",
    "\n",
    "submitted_mols = [return_canon(smi) for smi in submitted_mols]\n",
    "df_sub = pd.DataFrame(submitted_mols, columns=['smiles'])\n",
    "df2['cansmiles'] = [return_canon(smi) for smi in df2['smiles']]\n",
    "df_sub = df2[df2['cansmiles'].isin(submitted_mols)].drop_duplicates(subset=['cansmiles'], keep='first')\n",
    "\n",
    "# print(df_sub[~df_sub['smiles'].isin(df2['cansmiles'])].drop_duplicates(subset=['smiles'], keep='first'))\n",
    "# print(len(df2[df2['cansmiles'].isin(submitted_mols)].drop_duplicates(subset=['cansmiles'], keep='first')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sub['2body_score'].values)\n",
    "print(actual_scores_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "%matplotlib inline\n",
    "\n",
    "# actual_scores = []\n",
    "# # for i,row in tqdm(df2[df2['dir'].str.contains('rds-d2')].iterrows(), total=len(df2[df2['dir'].str.contains('rds-d2')])):\n",
    "# for i,row in tqdm(df2.iterrows(), total=len(df2)):\n",
    "#     smi = row['smiles']\n",
    "#     path = row['dir']\n",
    "#     df = pd.read_csv(path+'/scores_acc.csv')\n",
    "#     actual_score = df[df['smiles']==smi]['2body_score'].values[0]\n",
    "#     actual_scores.append(actual_score)\n",
    "\n",
    "# actual_scores = np.array(actual_scores)\n",
    "# # print(actual_scores)\n",
    "# _, bins, _ = plt.hist(actual_scores[actual_scores<10], bins=30, alpha=0.7, histtype='stepfilled', \n",
    "#          label='Including Don-Acc')\n",
    "# plt.hist(df2['2body_score'].values, bins=bins, alpha=0.7, histtype='stepfilled', \n",
    "#           label='Submitted Scores')\n",
    "         \n",
    "    \n",
    "# actual_scores_sub = []\n",
    "n_wrong = 0\n",
    "for i,row in tqdm(df_sub.iterrows(), total=len(df_sub)):\n",
    "    smi = row['smiles']\n",
    "    path = row['dir']\n",
    "    ind = row['ind']\n",
    "    df = pd.read_csv(path+'/scores_acc.csv')\n",
    "    actual_score = df[df['smiles']==smi]['2body_score'].values[0]\n",
    "    if actual_score != row['2body_score']:\n",
    "        print(path)\n",
    "        print(smi)\n",
    "        print(actual_score)\n",
    "        print(row['2body_score'])\n",
    "        n_wrong+=1\n",
    "print(n_wrong)\n",
    "#     actual_scores_sub.append(actual_score)\n",
    "    \n",
    "# actual_scores_sub = np.array(actual_scores_sub)\n",
    "# _, bins, _ = plt.hist(actual_scores_sub, bins=10, alpha=0.7, histtype='stepfilled', \n",
    "#          label='Including Don-Acc')\n",
    "# print(bins)\n",
    "# print(actual_scores_sub)\n",
    "# plt.hist(df_sub['2body_score'].values, bins=bins, alpha=0.7, histtype='stepfilled', \n",
    "#           label='Submitted Scores')    \n",
    "    \n",
    "# plt.hist([x, y], density=True, bins=bins) # alternating\n",
    "\n",
    "plt.title('top-N Molecules')\n",
    "# plt.title('Submitted Molecules')\n",
    "\n",
    "plt.xlabel('2body_score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.xlim(right=10)\n",
    "plt.show()\n",
    "# print(len(df_sub['2body_score'].values))\n",
    "# print(len(actual_scores_sub[actual_scores_sub<10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "missing_mols = ['Cc1[nH]c2ccccc2c1C(=O)NNc1nc2cccnc2s1', 'O=C(NNc1nc2ccccc2[nH]1)c1cc(O)nc2ccccc12']\n",
    "\n",
    "fp_missing = [AllChem.GetMorganFingerprintAsBitVect(MolFromSmiles(smi), radius=3, nBits=1024) for smi in missing_mols]\n",
    "fps = [AllChem.GetMorganFingerprintAsBitVect(MolFromSmiles(smi), radius=3, nBits=1024) for smi in df2['cansmiles']]\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for i in range(len(fp_missing)):\n",
    "    print('\\n{}'.format(missing_mols[i]))\n",
    "    for j in range(len(fps)):\n",
    "        sim = DataStructs.FingerprintSimilarity(fp_missing[i], fps[j])\n",
    "        if sim>threshold:\n",
    "            print(df2.iloc[j]['cansmiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "dirs_to_dl = df1['dir'].value_counts()\n",
    "rescore_dirs = []\n",
    "for path in tqdm(dirs_to_dl.index):\n",
    "        pairs = [file for file in os.listdir(path) if \"pairs_mpi_\" in file]\n",
    "        if len(pairs)!=0:\n",
    "            print(len(pairs))\n",
    "        smi_len = len(open(path+'/mols.smi','r').read().splitlines())\n",
    "        pickle_len = len(pickle.load(open(path+'/pairs.pickle','rb')))\n",
    "        \n",
    "        if smi_len != pickle_len:\n",
    "#             print(path)\n",
    "#             print(smi_len, pickle_len)\n",
    "            rescore_dirs.append(path)\n",
    "            \n",
    "print('Num bad dirs: {}'.format(len(rescore_dirs)))\n",
    "\n",
    "print(len(df1))\n",
    "print(len(df1[df1['dir'].str.contains('rds-d2')]))\n",
    "print(len(df1[df1['dir'].str.contains('rds-d7')]))\n",
    "\n",
    "# good_dirs = \n",
    "# score_dirs = df_tot.groupby('dir')\n",
    "\n",
    "print(len(df1[~df1['dir'].isin(rescore_dirs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_to_dl = df2['dir'].value_counts()\n",
    "rescore_dirs = []\n",
    "for path in tqdm(dirs_to_dl.index):\n",
    "        pairs = [file for file in os.listdir(path) if \"pairs_mpi_\" in file]\n",
    "        if len(pairs)!=0:\n",
    "            print(len(pairs))\n",
    "        smi_len = len(open(path+'/mols.smi','r').read().splitlines())\n",
    "        pickle_len = len(pickle.load(open(path+'/pairs.pickle','rb')))\n",
    "        \n",
    "        if smi_len != pickle_len:\n",
    "#             print(path)\n",
    "#             print(smi_len, pickle_len)\n",
    "            rescore_dirs.append(path)\n",
    "            \n",
    "print('Num bad dirs: {}'.format(len(rescore_dirs)))\n",
    "\n",
    "print(len(df2))\n",
    "print(len(df2[df2['dir'].str.contains('rds-d2')]))\n",
    "print(len(df2[df2['dir'].str.contains('rds-d7')]))\n",
    "\n",
    "# good_dirs = \n",
    "# score_dirs = df_tot.groupby('dir')\n",
    "\n",
    "print(len(df2[~df2['dir'].isin(rescore_dirs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirs_to_dl = df_tot['dir'].value_counts()\n",
    "print(len(dirs_to_dl))\n",
    "\n",
    "\n",
    "tranches = open(dir+'/all_tranches.txt','r').read().splitlines()\n",
    "tranches_to_dl = []\n",
    "for path in dirs_to_dl.index:\n",
    "    fold = path[-6:]\n",
    "    for tranch in tranches:\n",
    "        if fold in tranch:\n",
    "            tranches_to_dl.append(tranch)\n",
    "            \n",
    "print(len(tranches_to_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(dirs_to_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranches = open(dir+'/all_tranches.txt','r').read().splitlines()\n",
    "tranches_to_dl = []\n",
    "for path in rescore_dirs:\n",
    "    fold = path[-6:]\n",
    "    for tranch in tranches:\n",
    "        if fold in tranch:\n",
    "            tranches_to_dl.append(fold)\n",
    "\n",
    "f = open('/rds-d7/project/rds-ZNFRY9wKoeE/val_dir/rescore_folds.txt', 'w')\n",
    "for line in tranches_to_dl:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mols2grid\n",
    "# \n",
    "# df1 = df1.rename(columns={'smiles':'SMILES'})\n",
    "# df2 = df2.rename(columns={'smiles':'SMILES'})\n",
    "\n",
    "# mols2grid.display(df1, template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES'])\n",
    "mols2grid.display(df2, template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES', '2body_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mols2grid\n",
    "\n",
    "# print(df_tot)\n",
    "# df_tot = pd.concat([df_all, df_all_2]).sort_values(by='2body_score')\n",
    "# df_tot = df_tot.iloc[:min(N, len(df_all_2))]\n",
    "# df_tot = df_tot.rename(columns={'smiles':'SMILES'})\n",
    "# df_all = df_all.rename(columns={'smiles':'SMILES'})\n",
    "# df_all_2 = df_all_2.rename(columns={'smiles':'SMILES'})\n",
    "# mols2grid.display(df_all, nrows=6, subset=[\"img\"], tooltip=['SMILES'])\n",
    "# mols2grid.display(df_all, template=\"table\", n_cols=5, subset=[\"img\"], tooltip=['SMILES'])\n",
    "# mols2grid.display(df_all, template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES'])\n",
    "# mols2grid.display(df_all_2, template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES'])\n",
    "mols2grid.display(df_all.rename(columns={'smiles':'SMILES'}), template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES'])\n",
    "# page = mols2grid.to_pages(df_all, tooltip=['SMILES'], nrows=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols2grid.save(df_tot, template=\"pages\", n_rows=10, n_cols=5, subset=[\"img\"], tooltip=['SMILES'], \n",
    "               output=dir2+'topN_grid_acc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate previous top-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('~/topN_final_acc.csv')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
